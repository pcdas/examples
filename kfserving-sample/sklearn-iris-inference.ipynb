{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create my own model to test Scikit-Learn server\n",
    "* The model need to be built using the same python package dependency that kubeflow ships a specific version of sklearnserver with. Without adherence to this constraint, the model deserialization during serving time would fail. the deployed inference service will not start successfully.\n",
    "* See https://github.com/kubeflow/kfserving/blob/master/python/sklearnserver/setup.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import svm\n",
    "from sklearn import datasets\n",
    "from joblib import dump\n",
    "clf = svm.SVC(gamma='scale')\n",
    "iris = datasets.load_iris()\n",
    "X, y = iris.data, iris.target\n",
    "clf.fit(X, y)\n",
    "dump(clf, 'model.joblib')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Copy the model to S3/Minio for serving input\n",
    "* mc is a minio client that will need to be installed\n",
    "```bash\n",
    "$ mc config host list\n",
    "<<-- output snipped -->>\n",
    "k8s\n",
    "  URL       : http://minio-service.kubeflow.svc.cluster.local:9000\n",
    "  AccessKey : minio\n",
    "  SecretKey : minio123\n",
    "  API       : S3v4\n",
    "  Lookup    : auto\n",
    "<<-- output snipped -->>\n",
    "$ mc mb k8s/kfserving-samples # create the toplevel bucket\n",
    "$ mc cp model.joblib k8s/kfserving-samples/models/sklearn/iris/model.joblib # copy the model to S3\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create yaml specifications for deploying to KFServing system"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "namespace='pdas'\n",
    "account_name='sa'\n",
    "model_name=\"sklearn-iris\"\n",
    "\n",
    "s3_secret=f\"\"\"apiVersion: v1\n",
    "kind: Secret\n",
    "metadata:\n",
    "  name: mysecret\n",
    "  namespace: {namespace}\n",
    "  annotations:\n",
    "     serving.kubeflow.org/s3-endpoint: minio-service.kubeflow:9000 # replace with your s3 endpoint\n",
    "     serving.kubeflow.org/s3-usehttps: \"0\" # by default 1, for testing with minio you need to set to 0\n",
    "type: Opaque\n",
    "data:\n",
    "  awsAccessKeyID: bWluaW8=\n",
    "  awsSecretAccessKey: bWluaW8xMjM=\n",
    "\"\"\"\n",
    "\n",
    "service_account=f\"\"\"apiVersion: v1\n",
    "kind: ServiceAccount\n",
    "metadata:\n",
    "  name: {account_name}\n",
    "  namespace: {namespace}\n",
    "secrets:\n",
    "  - name: mysecret\n",
    "\"\"\"\n",
    "\n",
    "sklearn_inference=f\"\"\"apiVersion: \"serving.kubeflow.org/v1alpha2\"\n",
    "kind: \"InferenceService\"\n",
    "metadata:\n",
    "  name: \"{model_name}\"\n",
    "  namespace: {namespace}\n",
    "spec:\n",
    "  default:\n",
    "    predictor:\n",
    "      serviceAccountName: {account_name}\n",
    "      sklearn:\n",
    "        runtimeVersion: \"v0.3.0\"\n",
    "        storageUri: \"s3://kfserving-samples/models/sklearn/iris\"\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Submit KFServing yaml specifications to k8s API server\n",
    "* The programmatic actions are equivalent to following commands:\n",
    "```bash\n",
    "$ kubectl apply -f s3_secret.yaml\n",
    "$ kubectl apply -f service_account.yaml\n",
    "$ kubectl apply -f sklearn_inference.yaml\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(s3_secret)\n",
    "with open(\"s3_secret.yaml\", \"w\") as f:\n",
    "    f.write(s3_secret)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(service_account)\n",
    "with open(\"service_account.yaml\", \"w\") as f:\n",
    "    f.write(service_account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sklearn_inference)\n",
    "with open(\"sklearn_inference.yaml\", \"w\") as f:\n",
    "    f.write(sklearn_inference)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "secret/mysecret created\n",
      "serviceaccount/sa created\n",
      "inferenceservice.serving.kubeflow.org/sklearn-iris created\n"
     ]
    }
   ],
   "source": [
    "!kubectl apply -f s3_secret.yaml\n",
    "!kubectl apply -f service_account.yaml\n",
    "!kubectl apply -f sklearn_inference.yaml"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input data for testing Iris inference service"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "iris_input_json={\n",
    "  \"instances\": [\n",
    "    [6.8,  2.8,  4.8,  1.4],\n",
    "    [6.0,  3.4,  4.5,  1.6]\n",
    "  ]\n",
    "}\n",
    "print(iris_input_json)\n",
    "with open(\"iris_input.json\", \"w\") as f:\n",
    "    json.dump(iris_input_json, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test the deployed model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "curl -H \"Host: sklearn-iris-predictor-default.pdas.svc.cluster.local\" http://sklearn-iris-predictor-default.pdas.svc.cluster.local/v1/models/sklearn-iris:predict -d @./iris_input.json\n",
      "b'{\"predictions\": [1, 1]}'\n"
     ]
    }
   ],
   "source": [
    "inference_service_dns=f\"{model_name}-predictor-default.{namespace}.svc.cluster.local\"\n",
    "inference_service_url=f\"http://{inference_service_dns}/v1/models/{model_name}:predict\"\n",
    "curl_command=f'curl -H \"Host: {inference_service_dns}\" {inference_service_url} -d @./iris_input.json'\n",
    "print(curl_command)\n",
    "import subprocess\n",
    "cp=subprocess.run([\"curl\", \"-H\", f\"Host: {inference_service_dns}\", inference_service_url,\n",
    "                   \"-d\", \"@./iris_input.json\" ], stdout=subprocess.PIPE)\n",
    "print(f\"{cp.stdout}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Clean up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!kubectl delete -f sklearn_inference.yaml\n",
    "!kubectl delete -f service_account.yaml\n",
    "!kubectl delete -f s3_secret.yaml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
